{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "566103f9-e24e-44df-ab9a-fbb9fe5c206a",
   "metadata": {},
   "source": [
    "# Autoregressive LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c15b0-2f5d-4954-922f-d728f9c56fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "print('NumPy version: %s'%np.__version__)\n",
    "print('Pandas version: %s'%pd.__version__)\n",
    "print('Matplotlib version: %s'%mpl.__version__)\n",
    "print('TensorFlow version: %s'%tf.__version__)\n",
    "print('Keras version: %s'%keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5350ba-9df2-493d-bb95-d11ad0d0280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(url):\n",
    "  r = requests.get(url)\n",
    "  data_path = url.rsplit('/')[-1]\n",
    "  with open(data_path, 'wb') as f:\n",
    "    f.write(r.content)\n",
    "  return data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f39c0e4-b017-4289-bbb5-d8d328e6cdb2",
   "metadata": {},
   "source": [
    "## Dataset and data window\n",
    "We download the traffic datasets and define the data structure to build the batches of tensors for training, validation, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943fa5a-c940-497a-b593-a95040dc83fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = 'https://raw.githubusercontent.com/luigiselmi/timeseries/main/data/metro_interstate_traffic/train.csv'\n",
    "val_url = 'https://raw.githubusercontent.com/luigiselmi/timeseries/main/data/metro_interstate_traffic/val.csv'\n",
    "test_url = 'https://raw.githubusercontent.com/luigiselmi/timeseries/main/data/metro_interstate_traffic/test.csv'\n",
    "train_data = download_data(train_url)\n",
    "val_data = download_data(val_url)\n",
    "test_data = download_data(test_url)\n",
    "train_df = pd.read_csv(train_data, index_col=0)\n",
    "val_df = pd.read_csv(val_data, index_col=0)\n",
    "test_df = pd.read_csv(test_data, index_col=0)\n",
    "\n",
    "print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac975320-f049-4094-802d-6d1dd473022f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mDataWindow\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mlabel_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m, in \u001b[0;36mDataWindow\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDataWindow\u001b[39;00m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_width, label_width, shift,\n\u001b[1;32m----> 3\u001b[0m                  train_df\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_df\u001b[49m, val_df\u001b[38;5;241m=\u001b[39mval_df, test_df\u001b[38;5;241m=\u001b[39mtest_df,\n\u001b[0;32m      4\u001b[0m                  label_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_df \u001b[38;5;241m=\u001b[39m train_df\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_df \u001b[38;5;241m=\u001b[39m val_df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "class DataWindow():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                 train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "                 label_columns=None):\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def split_to_inputs_labels(self, features):\n",
    "        '''\n",
    "        This function separates inputs and labels from the features.\n",
    "        '''\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:,:,self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1\n",
    "            )\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def plot(self, model=None, plot_col='traffic_volume', max_subplots=3):\n",
    "        '''\n",
    "        The function plots the model's predictions for three data windows\n",
    "        '''\n",
    "        inputs, labels = self.sample_batch\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "\n",
    "        for n in range(max_n):\n",
    "            plt.subplot(3, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [scaled]')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "              label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "              label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "              continue\n",
    "\n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                        edgecolors='k', marker='s', label='Labels', c='green', s=64)\n",
    "            if model is not None:\n",
    "              predictions = model(inputs)\n",
    "              plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                          marker='X', edgecolors='k', label='Predictions',\n",
    "                          c='red', s=64)\n",
    "\n",
    "            if n == 0:\n",
    "              plt.legend()\n",
    "\n",
    "        plt.xlabel('Time (h)')\n",
    "\n",
    "    def make_dataset(self, data):\n",
    "        '''\n",
    "        This function is based on a Keras function to create batches of data by sliding windows of inputs and lables from the train, validation, and test sets.\n",
    "        The slide is set with the sequence_stride argument and it is set to 1. The data windows are shuffled but the order within each window is preserved.\n",
    "        '''\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=32\n",
    "        )\n",
    "\n",
    "        ds = ds.map(self.split_to_inputs_labels)\n",
    "        return ds\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "\n",
    "    @property\n",
    "    def sample_batch(self):\n",
    "        result = getattr(self, '_sample_batch', None)\n",
    "        if result is None:\n",
    "            result = next(iter(self.train))\n",
    "            self._sample_batch = result\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd5215e-68c4-40c9-a105-29505fd97e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model, window, patience=3, max_epochs=50):\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                   patience=patience,\n",
    "                                   mode='min')\n",
    "\n",
    "    model.compile(loss=keras.losses.MeanSquaredError(),\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(window.train,\n",
    "                       epochs=max_epochs,\n",
    "                       validation_data=window.val,\n",
    "                       callbacks=[early_stopping])\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b996d2-4eca-40d7-9b03-038fb18a218a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
