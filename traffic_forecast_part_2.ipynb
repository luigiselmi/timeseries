{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5abf8965",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/luigiselmi/timeseries/blob/main/traffic_forecast_part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2a345-cb56-412b-b8e6-d0a40fefc61e",
   "metadata": {
    "id": "3df2a345-cb56-412b-b8e6-d0a40fefc61e"
   },
   "source": [
    "# Metro Interstate Traffic Volume Forecasting (Part 2)\n",
    "This notebook is based on chapter 13 of the book [*Time Series Forecasting in Python*](https://www.manning.com/books/time-series-forecasting-in-python-book) by Marco Peixeiro. Classical algorithms for time series forecasting, are\n",
    "\n",
    "* $Moving Average MA(q)$\n",
    "* $Auto Regressive AR(p)$\n",
    "* $Autoregressive Moving Average ARMA(p,q)$\n",
    "* $Autoregressive Integrated Moving Average ARIMA(p,d,q)$\n",
    "* $SARIMA(p,d,q)(P,D,Q)_m$\n",
    "* $SARIMAX$\n",
    "\n",
    "where q is the order, or lag, of the time series, that is the number of previous elements in the series that are used for the forecast, p is the autocorrelation order, that is number of elements that are correlated, P and Q are the seasonal lag and autocorrelation order. These models try to fit a set of basis functions to the data depending on the chosen order $(p,d,q)(P,D,Q)_m$. With the neural networks we fit an unknown nonlinear function to the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a71a77ee-9bab-4365-98c0-9d900ff8aae0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a71a77ee-9bab-4365-98c0-9d900ff8aae0",
    "outputId": "01b68712-35c8-4137-bc4b-6bcb132db0f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.4\n",
      "Pandas version: 2.2.2\n",
      "Matplotlib version: 3.8.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "#import tensorflow as tf\n",
    "print('NumPy version: %s'%np.__version__)\n",
    "print('Pandas version: %s'%pd.__version__)\n",
    "print('Matplotlib version: %s'%mpl.__version__)\n",
    "#print('TensorFlow versiob: %s'%tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bIyfu8Nm-8py",
   "metadata": {
    "id": "bIyfu8Nm-8py"
   },
   "source": [
    "## Data windowing\n",
    "In order to train a model we split the data into time windows of the same length, for instance 24 hours. If the task is multistep forecasting, we use e.g. 24 hours as input data and the next 24 hours as target values so that a data window contains 48 hours. For example, the 1st window uses 48 hours starting from the 1st hour, the 2nd window uses 48 hours starting from the 2nd hour and so on. So there is an overlap of 47 hours between two consecutive data windows. We can create batches using a certain number of data windows, e.g. 32 data windows. The order for each data window cannot be changed but the order of the data windows in a batch can be shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7qY3RHi-IB3N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "7qY3RHi-IB3N",
    "outputId": "c6d18f02-e57c-44ca-fcd3-664600fd245e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33742, 4) (9641, 4) (4821, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/metro_interstate_traffic/train.csv', index_col=0)\n",
    "val_df = pd.read_csv('data/metro_interstate_traffic/val.csv', index_col=0)\n",
    "test_df = pd.read_csv('data/metro_interstate_traffic/test.csv', index_col=0)\n",
    "\n",
    "print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e286ffa-be73-4c68-9759-9da23b57c99e",
   "metadata": {},
   "source": [
    "## Deep learning model\n",
    "Deep learning model might perform better than classical time series models when the dataset available is large and contains signals that are complex. For example SARIMAX can be used only when there is only one kind of seasonality or cycle. In general deep learning model can be used when there is some nonlinear relationship between the input, in our example the meteorological variables and holidays and the target.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hcnvt7YXHv55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "hcnvt7YXHv55",
    "outputId": "8f672c07-7a1b-45df-a6bc-10fec86ad5a2"
   },
   "outputs": [],
   "source": [
    "class DataWindow():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                 train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "                 label_columns=None):\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def split_to_inputs_labels(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:,:,self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1\n",
    "            )\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def plot(self, model=None, plot_col='traffic_volume', max_subplots=3):\n",
    "        inputs, labels = self.sample_batch\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "\n",
    "        for n in range(max_n):\n",
    "            plt.subplot(3, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [scaled]')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "              label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "              label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "              continue\n",
    "\n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                        edgecolors='k', marker='s', label='Labels', c='green', s=64)\n",
    "            if model is not None:\n",
    "              predictions = model(inputs)\n",
    "              plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                          marker='X', edgecolors='k', label='Predictions',\n",
    "                          c='red', s=64)\n",
    "\n",
    "            if n == 0:\n",
    "              plt.legend()\n",
    "\n",
    "        plt.xlabel('Time (h)')\n",
    "\n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=32\n",
    "        )\n",
    "\n",
    "        ds = ds.map(self.split_to_inputs_labels)\n",
    "        return ds\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "\n",
    "    @property\n",
    "    def sample_batch(self):\n",
    "        result = getattr(self, '_sample_batch', None)\n",
    "        if result is None:\n",
    "            result = next(iter(self.train))\n",
    "            self._sample_batch = result\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4818cf-9279-46ba-8683-a7739f0b1482",
   "metadata": {
    "id": "0b4818cf-9279-46ba-8683-a7739f0b1482"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
